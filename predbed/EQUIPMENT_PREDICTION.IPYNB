{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HARSHDIP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 0.0847 - val_loss: 0.0599\n",
      "Epoch 2/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0667 - val_loss: 0.0550\n",
      "Epoch 3/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0700 - val_loss: 0.0419\n",
      "Epoch 4/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0684 - val_loss: 0.0580\n",
      "Epoch 5/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0657 - val_loss: 0.0441\n",
      "Epoch 6/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0633 - val_loss: 0.0644\n",
      "Epoch 7/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0710 - val_loss: 0.0647\n",
      "Epoch 8/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0678 - val_loss: 0.0634\n",
      "Epoch 9/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0629 - val_loss: 0.0546\n",
      "Epoch 10/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0676 - val_loss: 0.0544\n",
      "Epoch 11/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0600 - val_loss: 0.0424\n",
      "Epoch 12/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0652 - val_loss: 0.0493\n",
      "Epoch 13/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0633 - val_loss: 0.0626\n",
      "Epoch 14/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0607 - val_loss: 0.0375\n",
      "Epoch 15/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0590 - val_loss: 0.0407\n",
      "Epoch 16/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0603 - val_loss: 0.0520\n",
      "Epoch 17/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0582 - val_loss: 0.0659\n",
      "Epoch 18/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0610 - val_loss: 0.0451\n",
      "Epoch 19/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0575 - val_loss: 0.0441\n",
      "Epoch 20/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0562 - val_loss: 0.0485\n",
      "Epoch 21/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0642 - val_loss: 0.0612\n",
      "Epoch 22/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0621 - val_loss: 0.0512\n",
      "Epoch 23/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0553 - val_loss: 0.0483\n",
      "Epoch 24/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0587 - val_loss: 0.0392\n",
      "Epoch 25/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0631 - val_loss: 0.0470\n",
      "Epoch 26/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0548 - val_loss: 0.0608\n",
      "Epoch 27/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0563 - val_loss: 0.0594\n",
      "Epoch 28/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0561 - val_loss: 0.0501\n",
      "Epoch 29/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0574 - val_loss: 0.0551\n",
      "Epoch 30/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0552 - val_loss: 0.0549\n",
      "Epoch 31/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0584 - val_loss: 0.0734\n",
      "Epoch 32/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0583 - val_loss: 0.0677\n",
      "Epoch 33/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0606 - val_loss: 0.0431\n",
      "Epoch 34/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0597 - val_loss: 0.0499\n",
      "Epoch 35/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0531 - val_loss: 0.0614\n",
      "Epoch 36/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0561 - val_loss: 0.0574\n",
      "Epoch 37/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0563 - val_loss: 0.0579\n",
      "Epoch 38/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0563 - val_loss: 0.0520\n",
      "Epoch 39/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0559 - val_loss: 0.0611\n",
      "Epoch 40/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0542 - val_loss: 0.0448\n",
      "Epoch 41/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0556 - val_loss: 0.0659\n",
      "Epoch 42/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0565 - val_loss: 0.0605\n",
      "Epoch 43/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0551 - val_loss: 0.0612\n",
      "Epoch 44/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0561 - val_loss: 0.0562\n",
      "Epoch 45/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0553 - val_loss: 0.0637\n",
      "Epoch 46/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0553 - val_loss: 0.0506\n",
      "Epoch 47/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0522 - val_loss: 0.0644\n",
      "Epoch 48/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0545 - val_loss: 0.0601\n",
      "Epoch 49/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0548 - val_loss: 0.0478\n",
      "Epoch 50/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0526 - val_loss: 0.0521\n",
      "Epoch 51/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0535 - val_loss: 0.0735\n",
      "Epoch 52/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0486 - val_loss: 0.0501\n",
      "Epoch 53/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0540 - val_loss: 0.0451\n",
      "Epoch 54/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0525 - val_loss: 0.0482\n",
      "Epoch 55/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0514 - val_loss: 0.0647\n",
      "Epoch 56/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0519 - val_loss: 0.0625\n",
      "Epoch 57/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0515 - val_loss: 0.0516\n",
      "Epoch 58/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0542 - val_loss: 0.0705\n",
      "Epoch 59/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0477 - val_loss: 0.0627\n",
      "Epoch 60/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0510 - val_loss: 0.0559\n",
      "Epoch 61/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0488 - val_loss: 0.0496\n",
      "Epoch 62/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0450 - val_loss: 0.0485\n",
      "Epoch 63/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0445 - val_loss: 0.0584\n",
      "Epoch 64/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0475 - val_loss: 0.0566\n",
      "Epoch 65/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0493 - val_loss: 0.0552\n",
      "Epoch 66/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0468 - val_loss: 0.0446\n",
      "Epoch 67/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0451 - val_loss: 0.0667\n",
      "Epoch 68/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0416 - val_loss: 0.0561\n",
      "Epoch 69/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0430 - val_loss: 0.0452\n",
      "Epoch 70/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0411 - val_loss: 0.0513\n",
      "Epoch 71/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0388 - val_loss: 0.0608\n",
      "Epoch 72/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0395 - val_loss: 0.0683\n",
      "Epoch 73/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0390 - val_loss: 0.0627\n",
      "Epoch 74/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0388 - val_loss: 0.0688\n",
      "Epoch 75/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0350 - val_loss: 0.0608\n",
      "Epoch 76/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0334 - val_loss: 0.0733\n",
      "Epoch 77/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0359 - val_loss: 0.0550\n",
      "Epoch 78/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0336 - val_loss: 0.0853\n",
      "Epoch 79/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0378 - val_loss: 0.0609\n",
      "Epoch 80/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0327 - val_loss: 0.0702\n",
      "Epoch 81/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0359 - val_loss: 0.0801\n",
      "Epoch 82/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0321 - val_loss: 0.0711\n",
      "Epoch 83/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0337 - val_loss: 0.0598\n",
      "Epoch 84/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0319 - val_loss: 0.0639\n",
      "Epoch 85/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0301 - val_loss: 0.0498\n",
      "Epoch 86/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0334 - val_loss: 0.0564\n",
      "Epoch 87/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0312 - val_loss: 0.0640\n",
      "Epoch 88/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0287 - val_loss: 0.0569\n",
      "Epoch 89/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0258 - val_loss: 0.0680\n",
      "Epoch 90/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0304 - val_loss: 0.0766\n",
      "Epoch 91/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0292 - val_loss: 0.0925\n",
      "Epoch 92/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0288 - val_loss: 0.0647\n",
      "Epoch 93/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0306 - val_loss: 0.0854\n",
      "Epoch 94/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0282 - val_loss: 0.0644\n",
      "Epoch 95/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0248 - val_loss: 0.0821\n",
      "Epoch 96/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0254 - val_loss: 0.0726\n",
      "Epoch 97/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0228 - val_loss: 0.0565\n",
      "Epoch 98/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0248 - val_loss: 0.0730\n",
      "Epoch 99/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0226 - val_loss: 0.0684\n",
      "Epoch 100/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0229 - val_loss: 0.0679\n",
      "Trained and saved new model.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step\n",
      "Predicted Equipment for Tomorrow:\n",
      "Patient Monitors: 7.18\n",
      "Defibrillators: 3.56\n",
      "Infusion Pumps: 14.89\n",
      "Predicted: 7.18, Actual: 8.00\n",
      "Predicted: 3.56, Actual: 4.00\n",
      "Predicted: 14.89, Actual: 19.00\n",
      "Epoch 1/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0299\n",
      "Epoch 2/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0394\n",
      "Epoch 3/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0326\n",
      "Epoch 4/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0451\n",
      "Epoch 5/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0313\n",
      "Epoch 6/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0273\n",
      "Epoch 7/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0265\n",
      "Epoch 8/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0294\n",
      "Epoch 9/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0236\n",
      "Epoch 10/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0244\n",
      "Model updated with new data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"equipment_data.csv\")\n",
    "\n",
    "# Select features and targets\n",
    "features = [\n",
    "    \"Total_Admissions_Today\",\n",
    "    \"Total_Discharges_Today\",\n",
    "    \"ICU_Admissions_Today\",\n",
    "    \"Surgeries_Today\",\n",
    "    \"Bed_Occupancy_Rate\",\n",
    "    \"Is_Weekend\"\n",
    "]\n",
    "targets = [\"Patient_Monitors_Required\", \"Defibrillators_Required\", \"Infusion_Pumps_Required\"]\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = df.copy()\n",
    "df_scaled[features + targets] = scaler.fit_transform(df[features + targets])\n",
    "df_scaled[features + targets] = df_scaled[features + targets].astype(np.float32)\n",
    "\n",
    "# Train-Test Split (80% Train, 20% Test)\n",
    "train_size = int(len(df_scaled) * 0.8)\n",
    "train, test = df_scaled.iloc[:train_size], df_scaled.iloc[train_size:]\n",
    "\n",
    "# Function to create sequences for LSTM\n",
    "def create_sequences(data, seq_length=10):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data.iloc[i:i+seq_length][features].values)  # Features\n",
    "        y.append(data.iloc[i+seq_length][targets].values)  # Target\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare sequences\n",
    "seq_length = 10  # Model looks at last 10 days\n",
    "X_train, y_train = create_sequences(train, seq_length)\n",
    "X_test, y_test = create_sequences(test, seq_length)\n",
    "\n",
    "# Define LSTM Model\n",
    "def build_lstm_model():\n",
    "    model = Sequential([\n",
    "        LSTM(128, return_sequences=True, input_shape=(seq_length, len(features))),\n",
    "        Dropout(0.2),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32),\n",
    "        Dropout(0.2),\n",
    "        Dense(len(targets))  # Predicting multiple targets\n",
    "    ])\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# Path for saving model\n",
    "model_path = \"lstm_equipment_prediction.pkl\"\n",
    "\n",
    "# Load or Train Model\n",
    "if os.path.exists(model_path):\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model_json, weights = pickle.load(f)\n",
    "    model = model_from_json(model_json)\n",
    "    model.set_weights(weights)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    print(\"Loaded existing model.\")\n",
    "else:\n",
    "    model = build_lstm_model()\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "    # Save model\n",
    "    model_json = model.to_json()\n",
    "    weights = model.get_weights()\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump((model_json, weights), f)\n",
    "\n",
    "    print(\"Trained and saved new model.\")\n",
    "\n",
    "# Predict next day's equipment requirement\n",
    "latest_data = df_scaled.iloc[-seq_length:][features].values.reshape(1, seq_length, len(features))\n",
    "predicted_scaled = model.predict(latest_data)\n",
    "\n",
    "# Reverse scale the predictions\n",
    "predicted_full = np.zeros((1, len(features) + len(targets)))\n",
    "predicted_full[:, -len(targets):] = predicted_scaled.flatten()\n",
    "predicted_equipment = scaler.inverse_transform(predicted_full)[:, -len(targets):][0]  # Extract only target columns\n",
    "\n",
    "# Print predictions\n",
    "print(f\"Predicted Equipment for Tomorrow:\")\n",
    "print(f\"Patient Monitors: {predicted_equipment[0]:.2f}\")\n",
    "print(f\"Defibrillators: {predicted_equipment[1]:.2f}\")\n",
    "print(f\"Infusion Pumps: {predicted_equipment[2]:.2f}\")\n",
    "\n",
    "# Function to update the model with actual values\n",
    "def update_model_with_actual(actual_values):\n",
    "    \"\"\"\n",
    "    Updates the model with the new actual data at the end of the day.\n",
    "    \"\"\"\n",
    "    global df_scaled, X_train, y_train\n",
    "\n",
    "    # Add new actual data\n",
    "    new_data = df.iloc[-1:].copy()\n",
    "    for i, target in enumerate(targets):\n",
    "        new_data[target] = actual_values[i]  # Use actual entered values\n",
    "\n",
    "    # Normalize new data\n",
    "    new_data_scaled = new_data.copy()\n",
    "    new_data_scaled[features + targets] = scaler.transform(new_data[features + targets])\n",
    "\n",
    "    # Append new data\n",
    "    df_scaled = pd.concat([df_scaled, new_data_scaled])  # Keep growing dataset\n",
    "\n",
    "    # Re-create sequences\n",
    "    X_train, y_train = create_sequences(df_scaled, seq_length)\n",
    "\n",
    "    # Fine-tune model with new data\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=1)\n",
    "\n",
    "    # Save updated model\n",
    "    model_json = model.to_json()\n",
    "    weights = model.get_weights()\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump((model_json, weights), f)\n",
    "\n",
    "    print(\"Model updated with new data.\")\n",
    "\n",
    "# Get actual values entered by hospital staff\n",
    "actual_monitors = float(input(\"Enter actual Patient Monitors required: \"))\n",
    "actual_defibrillators = float(input(\"Enter actual Defibrillators required: \"))\n",
    "actual_pumps = float(input(\"Enter actual Infusion Pumps required: \"))\n",
    "\n",
    "# Compare and update\n",
    "print(f\"Predicted: {predicted_equipment[0]:.2f}, Actual: {actual_monitors:.2f}\")\n",
    "print(f\"Predicted: {predicted_equipment[1]:.2f}, Actual: {actual_defibrillators:.2f}\")\n",
    "print(f\"Predicted: {predicted_equipment[2]:.2f}, Actual: {actual_pumps:.2f}\")\n",
    "update_model_with_actual([actual_monitors, actual_defibrillators, actual_pumps])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step  \n",
      "R² Score for Doctors Prediction: 0.2106\n",
      "R² Score for Nurses Prediction: -0.8418\n",
      "R² Score for Technicians Prediction: 0.3263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "# Reverse scale the predictions\n",
    "y_pred_full = np.zeros((len(y_pred_scaled), len(features) + len(targets)))\n",
    "y_pred_full[:, -len(targets):] = y_pred_scaled  # Place predictions in target positions\n",
    "y_pred = scaler.inverse_transform(y_pred_full)[:, -len(targets):]  # Extract only target values\n",
    "\n",
    "# Reverse scale actual test values\n",
    "y_test_full = np.zeros((len(y_test), len(features) + len(targets)))\n",
    "y_test_full[:, -len(targets):] = y_test  # Place actual values in target positions\n",
    "y_actual = scaler.inverse_transform(y_test_full)[:, -len(targets):]  # Extract only target values\n",
    "\n",
    "# Compute R² score for each staff type\n",
    "r2_doctors = r2_score(y_actual[:, 0], y_pred[:, 0])\n",
    "r2_nurses = r2_score(y_actual[:, 1], y_pred[:, 1])\n",
    "r2_technicians = r2_score(y_actual[:, 2], y_pred[:, 2])\n",
    "\n",
    "# Display R² scores\n",
    "print(f\"R² Score for Doctors Prediction: {r2_doctors:.4f}\")\n",
    "print(f\"R² Score for Nurses Prediction: {r2_nurses:.4f}\")\n",
    "print(f\"R² Score for Technicians Prediction: {r2_technicians:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
